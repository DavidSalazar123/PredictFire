{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Goal is to predict the next time series within the sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Dense, Flatten, Input, LSTM, Dropout\n",
    "from tensorflow.keras.preprocessing.sequence import TimeseriesGenerator\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from keras_tuner import RandomSearch\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "from IPython import display\n",
    "from ann_visualizer.visualize import ann_viz "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DateTime</th>\n",
       "      <th>Holiday</th>\n",
       "      <th>Temperature</th>\n",
       "      <th>Snow_Depth</th>\n",
       "      <th>Wind_Speed</th>\n",
       "      <th>Clear</th>\n",
       "      <th>Cloudy</th>\n",
       "      <th>Overcast</th>\n",
       "      <th>Rain</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2001-01-03 15:00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>22.5</td>\n",
       "      <td>6.77</td>\n",
       "      <td>10.8</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2001-01-10 22:15:00</td>\n",
       "      <td>0</td>\n",
       "      <td>27.6</td>\n",
       "      <td>3.72</td>\n",
       "      <td>20.4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2001-01-11 18:30:00</td>\n",
       "      <td>0</td>\n",
       "      <td>35.5</td>\n",
       "      <td>3.72</td>\n",
       "      <td>14.6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2001-01-12 19:30:00</td>\n",
       "      <td>0</td>\n",
       "      <td>34.2</td>\n",
       "      <td>3.15</td>\n",
       "      <td>8.7</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2001-01-17 09:40:00</td>\n",
       "      <td>0</td>\n",
       "      <td>37.9</td>\n",
       "      <td>0.00</td>\n",
       "      <td>13.9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9051</th>\n",
       "      <td>2021-11-07 03:56:32</td>\n",
       "      <td>0</td>\n",
       "      <td>39.4</td>\n",
       "      <td>0.00</td>\n",
       "      <td>6.8</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9054</th>\n",
       "      <td>2021-11-10 08:13:41</td>\n",
       "      <td>0</td>\n",
       "      <td>51.8</td>\n",
       "      <td>0.00</td>\n",
       "      <td>15.4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9057</th>\n",
       "      <td>2021-11-13 14:56:29</td>\n",
       "      <td>0</td>\n",
       "      <td>41.9</td>\n",
       "      <td>0.00</td>\n",
       "      <td>15.6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9060</th>\n",
       "      <td>2021-11-16 20:14:30</td>\n",
       "      <td>0</td>\n",
       "      <td>38.2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>7.3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9062</th>\n",
       "      <td>2021-11-18 10:44:04</td>\n",
       "      <td>0</td>\n",
       "      <td>52.4</td>\n",
       "      <td>0.00</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4665 rows Ã— 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                DateTime  Holiday  Temperature  Snow_Depth  Wind_Speed  Clear  \\\n",
       "2    2001-01-03 15:00:00        0         22.5        6.77        10.8      0   \n",
       "9    2001-01-10 22:15:00        0         27.6        3.72        20.4      0   \n",
       "10   2001-01-11 18:30:00        0         35.5        3.72        14.6      0   \n",
       "11   2001-01-12 19:30:00        0         34.2        3.15         8.7      1   \n",
       "16   2001-01-17 09:40:00        0         37.9        0.00        13.9      0   \n",
       "...                  ...      ...          ...         ...         ...    ...   \n",
       "9051 2021-11-07 03:56:32        0         39.4        0.00         6.8      1   \n",
       "9054 2021-11-10 08:13:41        0         51.8        0.00        15.4      1   \n",
       "9057 2021-11-13 14:56:29        0         41.9        0.00        15.6      0   \n",
       "9060 2021-11-16 20:14:30        0         38.2        0.00         7.3      1   \n",
       "9062 2021-11-18 10:44:04        0         52.4        0.00        15.0      0   \n",
       "\n",
       "      Cloudy  Overcast  Rain  \n",
       "2          1         0     0  \n",
       "9          1         0     0  \n",
       "10         1         0     0  \n",
       "11         0         0     0  \n",
       "16         0         1     0  \n",
       "...      ...       ...   ...  \n",
       "9051       0         0     0  \n",
       "9054       0         0     0  \n",
       "9057       0         0     1  \n",
       "9060       0         0     0  \n",
       "9062       0         0     1  \n",
       "\n",
       "[4665 rows x 9 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"../datasets/LSTMdataset.csv\",index_col=0)\n",
    "df[\"DateTime\"] = pd.to_datetime(df[\"DateTime\"], format = \"%Y%m%d %H:%M:%S\")\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://machinelearningmastery.com/how-to-use-the-timeseriesgenerator-for-time-series-forecasting-in-keras/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "The DType <class 'numpy.dtype[datetime64]'> could not be promoted by <class 'numpy.dtype[float64]'>. This means that no common DType exists for the given inputs. For example they cannot be stored in a single array unless the dtype is `object`. The full list of DTypes is: (<class 'numpy.dtype[datetime64]'>, <class 'numpy.dtype[int64]'>, <class 'numpy.dtype[float64]'>, <class 'numpy.dtype[float64]'>, <class 'numpy.dtype[float64]'>, <class 'numpy.dtype[int64]'>, <class 'numpy.dtype[int64]'>, <class 'numpy.dtype[int64]'>, <class 'numpy.dtype[int64]'>)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [4], line 6\u001b[0m\n\u001b[0;32m      4\u001b[0m test_data \u001b[39m=\u001b[39m df[train_index:]\n\u001b[0;32m      5\u001b[0m scaler \u001b[39m=\u001b[39m MinMaxScaler(feature_range\u001b[39m=\u001b[39m(\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m,\u001b[39m1\u001b[39m)) \u001b[39m# This is used convert the values to 0-1 for model to learn quicker\u001b[39;00m\n\u001b[1;32m----> 6\u001b[0m scaler\u001b[39m.\u001b[39;49mfit(train_data)\n\u001b[0;32m      7\u001b[0m scaled_train \u001b[39m=\u001b[39m scaler\u001b[39m.\u001b[39mtransform(train_data)\n\u001b[0;32m      8\u001b[0m scaled_test \u001b[39m=\u001b[39m scaler\u001b[39m.\u001b[39mtransform(test_data)\n",
      "File \u001b[1;32mc:\\Users\\david\\anaconda3\\envs\\ML\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:420\u001b[0m, in \u001b[0;36mMinMaxScaler.fit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    418\u001b[0m \u001b[39m# Reset internal state before fitting\u001b[39;00m\n\u001b[0;32m    419\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reset()\n\u001b[1;32m--> 420\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpartial_fit(X, y)\n",
      "File \u001b[1;32mc:\\Users\\david\\anaconda3\\envs\\ML\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:457\u001b[0m, in \u001b[0;36mMinMaxScaler.partial_fit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    451\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\n\u001b[0;32m    452\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mMinMaxScaler does not support sparse input. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    453\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mConsider using MaxAbsScaler instead.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    454\u001b[0m     )\n\u001b[0;32m    456\u001b[0m first_pass \u001b[39m=\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39mhasattr\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mn_samples_seen_\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m--> 457\u001b[0m X \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_validate_data(\n\u001b[0;32m    458\u001b[0m     X,\n\u001b[0;32m    459\u001b[0m     reset\u001b[39m=\u001b[39;49mfirst_pass,\n\u001b[0;32m    460\u001b[0m     dtype\u001b[39m=\u001b[39;49mFLOAT_DTYPES,\n\u001b[0;32m    461\u001b[0m     force_all_finite\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mallow-nan\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m    462\u001b[0m )\n\u001b[0;32m    464\u001b[0m data_min \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mnanmin(X, axis\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m)\n\u001b[0;32m    465\u001b[0m data_max \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mnanmax(X, axis\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\david\\anaconda3\\envs\\ML\\lib\\site-packages\\sklearn\\base.py:577\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[1;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[0;32m    575\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mValidation should be done on X, y or both.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    576\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mnot\u001b[39;00m no_val_X \u001b[39mand\u001b[39;00m no_val_y:\n\u001b[1;32m--> 577\u001b[0m     X \u001b[39m=\u001b[39m check_array(X, input_name\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mX\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mcheck_params)\n\u001b[0;32m    578\u001b[0m     out \u001b[39m=\u001b[39m X\n\u001b[0;32m    579\u001b[0m \u001b[39melif\u001b[39;00m no_val_X \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m no_val_y:\n",
      "File \u001b[1;32mc:\\Users\\david\\anaconda3\\envs\\ML\\lib\\site-packages\\sklearn\\utils\\validation.py:768\u001b[0m, in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[0;32m    764\u001b[0m     pandas_requires_conversion \u001b[39m=\u001b[39m \u001b[39many\u001b[39m(\n\u001b[0;32m    765\u001b[0m         _pandas_dtype_needs_early_conversion(i) \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m dtypes_orig\n\u001b[0;32m    766\u001b[0m     )\n\u001b[0;32m    767\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mall\u001b[39m(\u001b[39misinstance\u001b[39m(dtype_iter, np\u001b[39m.\u001b[39mdtype) \u001b[39mfor\u001b[39;00m dtype_iter \u001b[39min\u001b[39;00m dtypes_orig):\n\u001b[1;32m--> 768\u001b[0m         dtype_orig \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39;49mresult_type(\u001b[39m*\u001b[39;49mdtypes_orig)\n\u001b[0;32m    770\u001b[0m \u001b[39mif\u001b[39;00m dtype_numeric:\n\u001b[0;32m    771\u001b[0m     \u001b[39mif\u001b[39;00m dtype_orig \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m dtype_orig\u001b[39m.\u001b[39mkind \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mO\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m    772\u001b[0m         \u001b[39m# if input is object, convert to float.\u001b[39;00m\n",
      "File \u001b[1;32m<__array_function__ internals>:180\u001b[0m, in \u001b[0;36mresult_type\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: The DType <class 'numpy.dtype[datetime64]'> could not be promoted by <class 'numpy.dtype[float64]'>. This means that no common DType exists for the given inputs. For example they cannot be stored in a single array unless the dtype is `object`. The full list of DTypes is: (<class 'numpy.dtype[datetime64]'>, <class 'numpy.dtype[int64]'>, <class 'numpy.dtype[float64]'>, <class 'numpy.dtype[float64]'>, <class 'numpy.dtype[float64]'>, <class 'numpy.dtype[int64]'>, <class 'numpy.dtype[int64]'>, <class 'numpy.dtype[int64]'>, <class 'numpy.dtype[int64]'>)"
     ]
    }
   ],
   "source": [
    "# Split training and test data (80% split)\n",
    "train_index = round(len(df) * .8)\n",
    "train_data = df[:train_index]\n",
    "test_data = df[train_index:]\n",
    "scaler = MinMaxScaler() # This is used convert the values to 0-1 for model to learn quicker\n",
    "scaler.fit(train_data)\n",
    "scaled_train = scaler.transform(train_data)\n",
    "scaled_test = scaler.transform(test_data)\n",
    "\n",
    "\n",
    "n_input = 3 #length of inputs to predict the output\n",
    "generator = TimeseriesGenerator(train_data,targets=train_data,length= n_input, batch_size = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(hp):\n",
    "    model = Sequential()\n",
    "\n",
    "    # Finds how many layers should be in NN\n",
    "    for layer in range(hp.Int(\"num_layers\", 1, 5)):\n",
    "        model.add(LSTM(units=hp.Int(\"units_\" + str(layer), min_value=100, max_value=250, step=25), input_shape=(9,1), activation=\"relu\", return_sequences=True))  # Find best amount of neurons for layer\n",
    "        model.add(Dropout(.2))\n",
    "    \n",
    "    model.add(Dense(1))\n",
    "    model.compile(optimizer=Adam(hp.Choice('learning_rate', values=[1e-2, 1e-4])), loss='mse', metrics=[\"mean_squared_error\"])  # Adam = SGD\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Search: Running Trial #1\n",
      "\n",
      "Value             |Best Value So Far |Hyperparameter\n",
      "2                 |?                 |num_layers\n",
      "225               |?                 |units_0\n",
      "0.01              |?                 |learning_rate\n",
      "\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Failed to convert a NumPy array to a Tensor (Unsupported object type Timestamp).",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [44], line 12\u001b[0m\n\u001b[0;32m      2\u001b[0m callback \u001b[39m=\u001b[39m EarlyStopping(monitor\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mloss\u001b[39m\u001b[39m\"\u001b[39m, min_delta\u001b[39m=\u001b[39m\u001b[39m.01\u001b[39m, patience\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[0;32m      3\u001b[0m tuner \u001b[39m=\u001b[39m RandomSearch(\n\u001b[0;32m      4\u001b[0m     build_model,\n\u001b[0;32m      5\u001b[0m     objective\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mval_accuracy\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     10\u001b[0m     executions_per_trial\u001b[39m=\u001b[39m\u001b[39m3\u001b[39m  \u001b[39m# How many times to train verison of model\u001b[39;00m\n\u001b[0;32m     11\u001b[0m )\n\u001b[1;32m---> 12\u001b[0m tuner\u001b[39m.\u001b[39;49msearch(train_data, callbacks\u001b[39m=\u001b[39;49m[callback], validation_split\u001b[39m=\u001b[39;49m\u001b[39m.5\u001b[39;49m)\n",
      "File \u001b[1;32mc:\\Users\\david\\anaconda3\\envs\\ML\\lib\\site-packages\\keras_tuner\\engine\\base_tuner.py:183\u001b[0m, in \u001b[0;36mBaseTuner.search\u001b[1;34m(self, *fit_args, **fit_kwargs)\u001b[0m\n\u001b[0;32m    180\u001b[0m     \u001b[39mcontinue\u001b[39;00m\n\u001b[0;32m    182\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mon_trial_begin(trial)\n\u001b[1;32m--> 183\u001b[0m results \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrun_trial(trial, \u001b[39m*\u001b[39mfit_args, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfit_kwargs)\n\u001b[0;32m    184\u001b[0m \u001b[39m# `results` is None indicates user updated oracle in `run_trial()`.\u001b[39;00m\n\u001b[0;32m    185\u001b[0m \u001b[39mif\u001b[39;00m results \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\david\\anaconda3\\envs\\ML\\lib\\site-packages\\keras_tuner\\engine\\tuner.py:295\u001b[0m, in \u001b[0;36mTuner.run_trial\u001b[1;34m(self, trial, *args, **kwargs)\u001b[0m\n\u001b[0;32m    293\u001b[0m     callbacks\u001b[39m.\u001b[39mappend(model_checkpoint)\n\u001b[0;32m    294\u001b[0m     copied_kwargs[\u001b[39m\"\u001b[39m\u001b[39mcallbacks\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m callbacks\n\u001b[1;32m--> 295\u001b[0m     obj_value \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_build_and_fit_model(trial, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mcopied_kwargs)\n\u001b[0;32m    297\u001b[0m     histories\u001b[39m.\u001b[39mappend(obj_value)\n\u001b[0;32m    298\u001b[0m \u001b[39mreturn\u001b[39;00m histories\n",
      "File \u001b[1;32mc:\\Users\\david\\anaconda3\\envs\\ML\\lib\\site-packages\\keras_tuner\\engine\\tuner.py:222\u001b[0m, in \u001b[0;36mTuner._build_and_fit_model\u001b[1;34m(self, trial, *args, **kwargs)\u001b[0m\n\u001b[0;32m    220\u001b[0m hp \u001b[39m=\u001b[39m trial\u001b[39m.\u001b[39mhyperparameters\n\u001b[0;32m    221\u001b[0m model \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_try_build(hp)\n\u001b[1;32m--> 222\u001b[0m results \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhypermodel\u001b[39m.\u001b[39mfit(hp, model, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    223\u001b[0m tuner_utils\u001b[39m.\u001b[39mvalidate_trial_results(\n\u001b[0;32m    224\u001b[0m     results, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moracle\u001b[39m.\u001b[39mobjective, \u001b[39m\"\u001b[39m\u001b[39mHyperModel.fit()\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    225\u001b[0m )\n\u001b[0;32m    226\u001b[0m \u001b[39mreturn\u001b[39;00m results\n",
      "File \u001b[1;32mc:\\Users\\david\\anaconda3\\envs\\ML\\lib\\site-packages\\keras_tuner\\engine\\hypermodel.py:140\u001b[0m, in \u001b[0;36mHyperModel.fit\u001b[1;34m(self, hp, model, *args, **kwargs)\u001b[0m\n\u001b[0;32m    116\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfit\u001b[39m(\u001b[39mself\u001b[39m, hp, model, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m    117\u001b[0m     \u001b[39m\"\"\"Train the model.\u001b[39;00m\n\u001b[0;32m    118\u001b[0m \n\u001b[0;32m    119\u001b[0m \u001b[39m    Args:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    138\u001b[0m \u001b[39m        If return a float, it should be the `objective` value.\u001b[39;00m\n\u001b[0;32m    139\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 140\u001b[0m     \u001b[39mreturn\u001b[39;00m model\u001b[39m.\u001b[39mfit(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\david\\anaconda3\\envs\\ML\\lib\\site-packages\\keras\\utils\\traceback_utils.py:67\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     65\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint: disable=broad-except\u001b[39;00m\n\u001b[0;32m     66\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[1;32m---> 67\u001b[0m   \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[0;32m     68\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m     69\u001b[0m   \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32mc:\\Users\\david\\anaconda3\\envs\\ML\\lib\\site-packages\\tensorflow\\python\\framework\\constant_op.py:102\u001b[0m, in \u001b[0;36mconvert_to_eager_tensor\u001b[1;34m(value, ctx, dtype)\u001b[0m\n\u001b[0;32m    100\u001b[0m     dtype \u001b[39m=\u001b[39m dtypes\u001b[39m.\u001b[39mas_dtype(dtype)\u001b[39m.\u001b[39mas_datatype_enum\n\u001b[0;32m    101\u001b[0m ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[1;32m--> 102\u001b[0m \u001b[39mreturn\u001b[39;00m ops\u001b[39m.\u001b[39;49mEagerTensor(value, ctx\u001b[39m.\u001b[39;49mdevice_name, dtype)\n",
      "\u001b[1;31mValueError\u001b[0m: Failed to convert a NumPy array to a Tensor (Unsupported object type Timestamp)."
     ]
    }
   ],
   "source": [
    "# Stop training when loss doesn't imporve in 1 epoches\n",
    "callback = EarlyStopping(monitor=\"loss\", min_delta=.01, patience=1)\n",
    "tuner = RandomSearch(\n",
    "    build_model,\n",
    "    objective='mse',\n",
    "    directory='LSTM_trails',  # Store results\n",
    "    project_name='LSTM_model',\n",
    "    overwrite=True, \n",
    "    max_trials=12,  # Bc 6 steps x 2 learning_rates\n",
    "    executions_per_trial=3  # How many times to train verison of model\n",
    ")\n",
    "tuner.search(generator, callbacks=[callback], validation_split=.5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 ('ML')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "407f5bce9b11530e19e06380f3610560da047a18a1d9e4ca7ed6b9fc09464b4d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
